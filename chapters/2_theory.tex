\section{Sisteme de recomandare}

\subsection{Noțiuni generale}

Sistemele de recomandare au scopul de a oferi sugestii cât mai relevante de articole utilizatorilor unei platforme pe baza unor strategii. Un sistem de recomandare poate folosi una sau mai multe strategii de recomandare după cum vom vedea în continuare. În cazul în care se folosesc cel puțin două strategii, sistemul de recomandare devine un sistem de recomandare hibrid. Prin folosirea mai multor strategii se urmărește ca fiecare strategie să vină în completarea celorlalte strategi cu avantajele sale. De cele mai multe ori, în implementarea unui sistem de recomandare se folosește tehnica de filtrare colaborativă împreună cu o altă strategie de recomandare \hyperlink{ErionCanoMaurizioMorisio}{[4]}.

\subsection{Strategii de recomandare}

\subsubsection*{Filtrarea colaborativă}

Filtrarea colaborativă se bazează pe faptul că utilizatorii care au în prezent preferințe similare vor avea și în viitor preferințe destul de similare. Această abordare folosește ratingurile pe care le dau utilizatorii sau oricare altă formă de a da un feedback, îmi place/nu îmi place, pentru a identifica preferințele comune dintre grupurile de utilizatori. Odată identificate preferințele se generează recomandări pe baza similarităților dintre utilizatori. 

Dezavantajul acestei strategii apare în momentul în care în sistem intră un nou utilizator. Datorită faptului că utilizatorul este nou, sistemul nu are un istoric al preferințelor lui, iar în consecință nu îl poate asigna unui grup de utilizatori pe baza preferințelor \hyperlink{ErionCanoMaurizioMorisio}{[4]}.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_1}
	\caption[Filtrarea colaborativă]{\textit{Filtrarea colaborativă. Imagine preluată din \hyperlink{datameetsmedia}{[5]}.}}
\end{figure} 

\subsubsection*{Filtrarea bazată pe conținut}

Filtrarea bazată pe conținut pleacă de la premisa că utiliztorii cărora le-au plăcut articole definite de anumite caracteristici în trecut, vor aprecia aceleași tip de articole și în viitor. Această abordare folosește caracteristicile articolelor pentru a le compara cu profilul utilizatorilor și a oferi recomandări. Calitatea recomandărilor rezultate folosind această strategie este influențată de setul de caracteristici ales pentru articole. Similar cu filtrarea colaborativă, filtrarea bazată pe conținut prezintă dezavantaje în momentul în care în sistem intră un nou utilizator fără istoric \hyperlink{ErionCanoMaurizioMorisio}{[4]}.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_2}
	\caption[Filtrarea bazată pe conținut]{\textit{Filtrarea bazată pe conținut. Imagine preluată din \hyperlink{datameetsmedia}{[5]}.}}
\end{figure} 

\subsubsection*{Filtrarea demografică}

Filtrarea demografică folosește atribute precum vârsta, genul, educația, etc. pentru a identifica categoriile de utilizatori. Nu prezintă dezavantaje atunci când apar noi utilizatori în sistem și nu se folosește de ratinguri, sau alt sistem de feedback, pentru a face recomandări.

Dezavantajul este reprezentat de faptul că procesul de colectare al datelor demografice poate fi îngreunat de legislație, fapt ce reprezintă o limitare a acestei metode \hyperlink{ErionCanoMaurizioMorisio}{[4]}.

\subsubsection*{Filtrarea bazată pe cunoștințe}

Filtrarea bazată pe cunoștințe folosește cunoștințele despre utilizatori și articole pentru a spune ce articole îndeplinesc cerințele utilizatorilor și genereaza recomandări în consecință. Filtrarea bazată pe cunoștințe are la bază constrângeri și este capabilă să recomande chiar și articole complexe care nu sunt cumpărate atât de des, precum mașini sau case \hyperlink{ErionCanoMaurizioMorisio}{[4]}.

\subsection{Funcții de eroare}

\subsubsection*{BPR: Bayesian Personalised Ranking}

Este o metodă ce se bazează pe feedback implicit (click-uri, ratinguri, achiziții, vizualizări). Exită multe metode ce se bazează pe acest feedback implicit, precum factorizarea matricială (MF), cei mai apropiați K vecini (kNN), însă acestea nu sunt optimizate pentru ranguri. Metoda de învățare este bazată pe gradientul descendent și este recomandată atunci când se dorește optimizarea acurateții.

Definim în continuare $U$ ca fiind mulțimea de utilizatori și $I$ ca fiind mulțimea de articole. Feedback-ul implicit este reprezentat de mulțimea $S \subseteq U \times I$. De asemenea, definim $I_u^+ := {i \in I:(u, i) \in S}$ și $U_i^+ := {u \in U:(u, i) \in S}$.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_8}
	\caption[Matricea de interacțiuni]{\textit{Matricea de interacțiuni, mulțimea $S$. Imagine preluată din \hyperlink{SteffenRendleChristophFreudenthalerZenoGantnerLarsSchmidtThieme}{[9]}.}}
\end{figure} 

O abordarea uzuală pentru recomandarea de articole este să fie estimat scorul $\hat{x}_{ui}$ care să reflecte preferința utilizatorului $u$ pentru articolul $i$. Apoi fiecare articol primește un rang după sortarea scorurilor.

Setul de antrenare (vezi figura 2.4) este definit de mulțimea $D_S := \{(u,i,j)|i \in I_u^+ \wedge j \in I \setminus I_u^+\}$ unde $(u,i,j)$ înseamnă că utilizatorul $u$ preferă articolul $i$ în detrimentul articolului $j$.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_9}
	\caption[Setul de antrenare]{\textit{Setul de antrenare. $+$ reprezintă articolele $i$ pe care utilizatorul le preferă în locul articolelor $j$, $-$ utilizatorul preferă articolele $j$ în loc de $i$, iar $?$ reprezintă lipsa informației despre acea interacțiune. Imagine preluată din \hyperlink{SteffenRendleChristophFreudenthalerZenoGantnerLarsSchmidtThieme}{[9]}.}}
\end{figure} 

Criteriul de optimizare pentru rangurile personalizate este definit după cum urmează:
\begin{align}
	loss_{BPR-OPT} := \sum_{(u,i,j) \in D_S} \ln{\sigma(\hat{x}_{uij})} - \lambda_\Theta||\Theta||^2
\end{align}
unde $\sigma$ este funcția sigmoid, $\sigma(x) := \frac{1}{1+e^{-x}}$, $\Theta$ reprezintă vectorul parametru al modelului care definește interacțiunea dintre utilizatorul $u$, articolul $i$ și articolul $j$, iar $\lambda_\Theta$ reprezintă parametrii de regularizare.

Cu aceste definiții putem defini și procedura de învățare a $BPR$ după cum urmează în figura 2.5:
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_10}
	\caption[Procedura de învățarea BPR]{\textit{Optimizarea modelului bazată metoda gradientului descendent cu parametrul de învățare $\alpha$ și regularizarea $\lambda_\Theta$. Imagine preluată din \hyperlink{SteffenRendleChristophFreudenthalerZenoGantnerLarsSchmidtThieme}{[9]}.}}
\end{figure}

\vspace{5mm}
\subsubsection*{WARP: Weighted Approximate-Rank}
Această metodă își are originile în procesarea imaginilor și anume pentru un set de reprezentări ale unor imagini $x \in \mathbb{R}^d$ și pentru un set de reprezentări ale unor adnotări $i \in \Upsilon = \{1, ..., Y\}$ - inidici intr-un dicționar cu posibile adnotări, metoda învață să mapeze imagini din spațiul reprezentărilor într-un spațiu comun $\mathbb{R}^D$
\begin{align}
	\Phi_{I}(x):\mathbb{R}^d \rightarrow \mathbb{R}^D
\end{align}
în același timp învățând și mapări pentru adnotări în același spațiu.
\begin{align}
	\Phi_{W}(i):\{1,...,Y\} \rightarrow \mathbb{R}^D
\end{align}

Principalul scop este de a oferi ranguri posibilelor adnotări pentru o imagine dată astfel încât cel mai mare rang să descrie cel mai bine conținutul semnatic al imaginii. 

Modelul folosit este definit în continuare:
\begin{align}
	f_{i}(x) = \Phi_{W}(i)^T \Phi_{I}(x)
\end{align}

Metoda învață să producă ranguri optimizate pentru primele adnotări din listă, ceea ce înseamnă că optimizează precizia@k.

În ceea ce privește funcția de eroare definim: $f(x) \in \mathbb{R}^Y$ ce produce un scor pentru fiecare etichetă și unde $f_i(x)$ este valoarea etichetei $i$. Definim funcția de eroare pentru ranguri ca fiind:
\begin{align}
	err(f(x),y) = L(rank_y(f(x)))
\end{align}
unde $rank_y(f(x))$ este rangul etichetei corecte dat de $f(x)$:
\begin{align}
	rank_y(f(x)) = \sum_{i \neq y}I(f_i(x) \geq f_y(x))
\end{align}
unde I este funcția indicator, iar $L(\cdot)$ transformă rangul în penalizare
\begin{align}
	L(k) = \sum_{j=1}^k\alpha_j, \quad cu \quad \alpha_1 \geq \alpha_2 \geq ... \geq 0.
\end{align}

$L(\cdot)$ poate lua diferite forme în funcție de ce se dorește a optimiza: $\alpha_j=\frac{1}{Y-1}$ optimizează rangul mediu, $\alpha_j=1$ și $\alpha_{j>1}=0$ optimizează proporția de ranguri corecte aflate în top, iar valorile mari ale lui $\alpha$ optimizează primele $k$ în lista de ranguri\hyperlink{JasonWestonSamyBengioNicolasUsunier}{[8]}.

Cu definițiile prezentate mai sus putem descrie algoritmul acestei metode după cum urmează.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_7}
	\caption[Online WARP Loss Optimization]{\textit{Online WARP Loss Optimization. Imagine preluată din \hyperlink{JasonWestonSamyBengioNicolasUsunier}{[8]}.}}
\end{figure} 

\vspace{5mm}
\subsubsection*{k-OS WARP}
Abordarea k-OS WARP a fost studiata în viața reală pe două sisteme, Google Music și YouTube unde au fost obținute îmbunătățiri ale metricilor de evaluare, iar în cazul YouTube a dus la creșterea numărului de clickuri și la creșterea duratei de vizionare \hyperlink{jasonkos}{[19]}.

Fie $D$ o mulțime de articole pentru un utilizator pentru care trebuie să se facă ranguri astfel încât cele mai relevante articole să fie în top. Fie $U$ o mulțime de antrenare de utilizatori cu o mulțime de ranguri cunoscute. Considerăm interacțiunile pozitive ca fiind date de articole pe care un utilizator le-a cumpărat, vizualizat, plăcut. Toate celelalte interacțiuni sunt considerate ca având ratinguri necunoscute. Definim $D_u$ ca reprezentând articolele pozitive pentru utilizatorul $u$. Modelul factorizat este următorul:
\begin{align}
	f_d(u) = \frac{1}{|D_u|} \sum_{i \in D_u} V_i^T V_d
\end{align}
unde $V$ este o matrice de dimensiune $m \times |D|$, câte un vector pentru fiecare articol conținând parametrii ce trebuie învățați. Definim în continuare $f(u)$ ca fiind vectorul tuturor scorurilor articolelor $1,...,|D|$ pentru un utilizator $u$. Pentru a învăța $f$, putem considera funcția de minimizare a obiectivului ca fiind:
\begin{align}
	\sum_{u=1}^{|U|}L(f(u),D_u)
\end{align}
unde $L$ este funcția de eroare care măsoară discrepanța dintre ratingurile cunoscute $D_u$ și predicțiile făcute pentru utilizatorul $u$. În acest sens putem defini două funcții de eroare: eroare AUC și eroare WARP.
\begin{align}
	L_{AUC}(f(u),D_u) = \sum_{d \in D_u} \sum_{\bar{d} \in D \setminus D_u} max(0, 1 - f_d(u) + f_{\bar{d}}(u))
\end{align}
Această funcție este optimizată prin metoda gradientului descendent, se selectează un utilizator, un articol pozitiv și un articol negativ aleator și se face un pas al gradientului.
Însă această funcție nu optimizează foarte bine rangurile elementelor din top. O funcție care face acest lucru mai bine este:
\begin{align}
	L_{WARP}(f(u), D_u) = \sum_{d \in D_u} \Phi(rank_d(f(u)))
\end{align}
unde $\Phi(n)$ convertește rangul elementului pozitiv $d$ într-o pondere unde rangul este definit după cum urmează:
\begin{align}
	rank_d{(u)} = \sum_{\bar{d} \not\in D_u} I(f_d(u) \geq 1 + f_{\bar{d}}(u))
\end{align}
unde $I$ este funcția indicator.

Pentru a generaliza funcțiile de mai sus se propune funcția de eroare numită \textit{k-Order Statistic (k-OS)} după cum urmează: pentru un utilizator dat, $u$, fie $o$ vectorul care indică ordinea elementelor pozitive în lista de ranguri $f_{D_{U_{o_1}}}(u) > f_{D_{U_{o_2}}}(u) > ... > f_{D_{U_{o{|s|}}}}(u)$.
\begin{align}
	L_{K-OS}(f(u),D_u) = \frac{1}{Z} \sum_{i=1}^{|D_u|}P(\frac{i}{|D_u|}\Phi(rank_{D_{u_{o_i}}}(f(u)))
\end{align}
unde $Z = \sum_iP(\frac{i}{|D_u|}$ normalizează ponderile introduse de $P$. $P(\frac{j}{100})$ este ponderea asignată fracțiunii $j$ a elementelor pozitiv ordonate. 

Cu aceste noțiuni definite putem defini alogoritmii pentru funcțiile de eroare AUC și WARP în contextul K-os după cum urmează în figura 2.8.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=12cm,max height=12cm,keepaspectratio]{img_2_27}
	\caption[Algoritmul k-os pentru alegerea unui element pozitiv]{\textit{Algoritmul k-os pentru alegerea unui element pozitiv. Imagine preluată din \hyperlink{jasonkos}{[19]}.}}
\end{figure} 

\begin{figure}[!tbp]
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_28}
    \caption{K-os WARP}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{img_2_29}
    \caption{K-os AUC}
    \label{fig:f2}
  \end{subfigure}
  \caption[Algoritmii k-os AUC și WARP]{\textit{Algoritmii k-os AUC și WARP. Imagine preluată din \hyperlink{jasonkos}{[19]}.}}
\end{figure}

\section{Optimizarea cu metoda gradientului descendent}
\subsection{Noțiuni generale}
Metoda gradientului descendent este unul dintre cei mai populari algoritmi folosiți pentru optimizarea rețelelor neurale. Metoda gradientului descendent presupune optimizarea funcției obiectiv, fie $J(\theta)$ - parametrizată cu parametrii modelului $\theta \in \mathbb{R}^d$, actualizând parametrii în direcția opusă gradientului funcției obiectiv $\nabla_{\theta}J(\theta)$. Rata de învățare $\eta$ determină dimensiunea pașilor pe care metoda îi face pentru a ajunge la minimul local \hyperlink{ruder2016}{[20]}.

\subsection{Variante ale metodei}
\subsubsection{Batch gradient descent}
Batch gradient descent calculează gradientul funcției de cost pentru întreg setul de antrenare:
\begin{align}
	\theta = \theta - \eta \cdot \nabla_{\theta}J(\theta)
\end{align}
Pentru a face o actualizare trebuie să calculăm gradienții pentru întreg setul, astfel gradientul descendent poate fi foarte încet. De asemenea nu se poate actualiza în timp real un model cu exemple noi.

Batch gradient descent converge garantat către un minim global pentru suprafețele convexe sau către un minim local pentru suprafețele nonconvexe.

\subsubsection{Stochastic gradient descent}
Spre deosebire de metoda prezentată anterior, stochastic gradient descent realizează o actualizare pentru fiecare exemplu de antrenare $x^{(i)}$ și pentru fiecare etichetă $y^{i}$:
\begin{align}
	\theta = \theta - \eta \cdot \nabla_{\theta}J(\theta;x^{(i)};y^{i})
\end{align}
Această abordare realizează calcule redundante pentru un set de antrenare mare în sensul că recalculează gradienți pentru exemple similare. Această redundanță poate fi eliminată printr-o singură actualizare la un anumit moment, ceea ce o face și mai rapidă. Metoda prezintă fluctuații puternice. Fluctuațiile pot ajuta metoda să ajungă la un minim local mai bun însă aceste fluctuații pot convergența către un minim global. Din punct de vedere al convergenței această metodă converge către un minim global pentru suprafețele convexe sau către un minim local pentru suprafețele nonconvexe.

\subsubsection{Mini-batch gradient descent}
Mini-batch gradient descent poate fi considerată ca o îmbinare a celor mai bune părți din cele două metode prezentate mai sus în sensul că se realizează o actualizare pentru fiecare mini-batch de $n$ exemple de antrenare:
\begin{align}
	\theta = \theta - \eta \cdot \nabla_{\theta}J(\theta;x^{(i:i+n)};y^{(i:i+n)})
\end{align} 
În această abordare pot fi remarcate: a) poate conduce către o convergență mai stabilă prin reducerea varianței parametrilor actualizați; b) poate folosi foarte optimizat optimizarea matricelor.

Cele mai comune valori alese pentru dimensiunea mini-batchurilor sunt cuprinse între 50 și 256, însă aceste valori pot varia foarte mult de la aplicație la aplicație.

\subsection{Algoritmi de optimizare}
\subsubsection{Adagrad}
Adagrad este un algoritm utilizat pentru optimizarea gradientului care își adaptează rata de învățarea la parametrii, fiind potrivi pentru seturi de date sparse \hyperlink{adagrad}{[25]}. 

Adagrad utilizează o rată de învățare diferită pentru fiecare parametru $\theta_i$ la fiecare pas $t$. Vom seta $g_{t,i}$ ca fiind gradientul funcției obiectiv cu parametrul $\theta_i$ la pasul $t$:
\begin{align}
	g_{t,i} = \nabla_{\theta_t}J(\theta_t, i)
\end{align}
Algoritmul modifică rata generală de învățare la fiecare pas $t$ pentru fiecare parametru $\theta_i$ bazânduse pe gradienții precedenți calculați pentru $\theta_i$:
\begin{align}
	\theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}
\end{align}
unde $G_t \in \mathbb{R}^{d \times d}$ este o matrice diagonală unde fiecare element de pe diagonala, $(i,i)$, reprezintă suma pătratelor gradienților, $\epsilon$ este o variabilă cu valoare mică, de obicei $1e-8$ folosită pentru a evita împărțirea la 0.

Unul dintre principalele avantaje pe care îl aduce algoritmul de optimizare Adagrad este reprezentat de faptul că elimină necesitatea de a tuna manual rata de învățare, care de cele mai multe ori este setata la $0.01$ și de prea puține ori modificată.

\section{Modelul LightFM}
Modelul LightFM este un model hibrid de factorizare matricială în care utilizatorii și articolele sunt reprezentate sub formă de combinații liniare a factorilor latenți a caracteristicilor. Modelul fiind hibrid, utilizează două strategii de învățare și anume învățarea colaborativă și filtrarea bazată pe conținut.

\vspace{5mm}
Cerințele de la care a fost dezvoltată structura modelului LightFM sunt \hyperlink{maciejlightfm}{[18]}:
\begin{enumerate}
	\item Modelul trebui să învețe reprezentările utilizatorilor și articolelor din datele de interacțiune: această cerință este realizată prin utilizarea reprezentărilor latente. De exemplu, dacă două articole, fie $X$ și $Y$, sunt apreciate de aceași utilizatori, atunci reprezentările celor două articole, $X$ și $Y$, vor fi apropiate. Pe de altă parte, dacă articolele $X$ și $Y$ nu sunt apreciate de aceași utilizatori, atunci reprezentările celor două articole vor fi îndepărtate. Astfel, dacă reprezentările celor două articole $X$ și $Y$ sunt similare putem recomanda cu un grad ridicat de încredere articolul $Y$ unui utilizator dacă acel utilizator a interacționat cu articolul $X$;
	\item Modelul trebuie să poată face recomandări pentru articole și utilizatori noi: această cerință este indeplinită prin reprezentarea articolelor și utilizatorilor sub formă de combinații liniare a caracteristicilor. Se aplică această abordare deoarece caracteristicile unui articol sau utilizator sunt cunoscute în momentul în care intră în sistem (de cele mai multe ori). De exemplu, un film științifico-fantastic cu Leonardo DiCaprio poate fi reprezentat ca sumă a reprezentării genului științifico-fantastic și a reprezentării actorului Leonardo DiCaprio. Un utilizator masculin din România poate fi reprezentat ca sumă a reprezentării utilizatorilor masculini și reprezentării țării România.
\end{enumerate}

\vspace{5mm}
Din punct de vedere formal modelul LightFM este definit după cum urmează în continuare \hyperlink{maciejlightfm}{[18]}: fie $U$ mulțimea de utilizatori, $I$ mulțimea de articole, $F^U$ mulțimea caracteristicilor utilizatorilor, $F^I$ mulțimea caracteristicilor articolelor. Fiecare utilizator interacționează cu un număr de elemente prin interacțiuni pozitive sau prin interacțiuni negative. Mulțimea tuturor interacțiunilor utilizator - articol este definită ca $(u,i) \in U \times I$, unde în această reuniune sunt incluse atât interacțiunile pozitive cât și interacțiunile negative.

Utilizatorii și articolele sunt complet descrise de caracteristicile lor. Fiecare user $u$ este descris de un set de caracteristici $f_u \subset F^U$. Similar și pentru fiecare articol $i$, este descris de un set de caracteristici $f_i \subset F^I$. Caracteristicile sunt cunoscute dinainte și sunt reprezentate de metadatele utilizatorilor sau articolelor.

Modelul este parametrizat d-dimensional pentru caracteristicile encodate ale utilizatorilor și articolelor și anume $e_f^U$ și $e_f^I$ pentru fiecare caracteristică $f$. Fiecărui feature i se mai adaugă un bias, $b_f^U$ pentru caracteristicile utilizatorilor și $b_f^I$ pentru caracteristicile articolelor.

Reprezentarea latentă a unui utilizator $u$ este dată de suma vectorilor latenți de caracteristici:
\begin{align}
	q_u = \sum_{j \in f_u} e_j^U
\end{align}
Similar și pentru articolul $i$:
\begin{align}
	p_i = \sum_{j \in f_i} e_j^I
\end{align}
Biasul pentru utilizatorul $u$ este dat de suma biasurilor caracteristicilor:
\begin{align}
	b_u = \sum_{j \in f_u} b_j^U
\end{align}
Similar și pentru articolul $i$:
\begin{align}
	b_i = \sum_{j \in f_i} b_j^I
\end{align}

Predicția modelului pentru utilizatorul $u$ și articolul $i$ este dată de produsul dintre reprezentarea utilizatorului și reprezentarea articolului, ajustată cu biasurile pentru utilizator și articol:
\begin{align}
	\hat{r_{ui}} = f(q_u \cdot p_i + b_u + b_i)
\end{align}
unde $f$ poate fi reprezentat de multe tipuri de funcții. În acest model $f$ este setat ca fiind funcția sigmoid:
\begin{align}
	f(x) = \frac{1}{1 + exp(-x)}
\end{align}

Obiectivul de optimizare al modelului constă în maximizarea următoarei probabilității:
\begin{align}
	L(e^U, e^I, b^U, b^I) = \prod_{(u,i) \in S^+} \hat{r}_{ui} \times \prod_{(u,i) \in S^-} (1 -\hat{r}_{ui})
\end{align}

\section{Rețele neurale convoluționale}

\subsection{Noțiuni generale}

Rețelele neurale convoluționale sunt rețelele formate din neuroni ce învață ponderi ($w$) și biasuri ($b$). În mod uzual rețelele convoluționale sunt folosite pe matrici pe care învăță parametrii, iar ultimele straturi din aceste rețele produc etichete. 

Spre exemplu, la input se dă o imagine cu un autovehicul, iar rețeaua convoluțională poate spune că în imagine este o mașină în proporție de 80\%, un camion în proporție de 10\%, un avion în proporție de 6\%, o barcă în proporție de 3\% sau un cal în proporție de 1\%.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_3}
	\caption[Exemplu rețea convoluțională]{\textit{Exemplu de rețea convoluțională care primește la input o imagine și produce la output o listă de clase ce pot descrie imaginea de input. Imagine preluată din \hyperlink{datameetsmedia}{[7]}.}}
\end{figure} 

Rețelele convoluționale sunt compuse dintr-o secvență de straturi ce poate fi împărțită în trei tipuri principale \hyperlink{cs231n}{[7]}:
\begin{enumerate}
  \item Stratul convoluțional este stratul de bază într-o rețea. Parametrii acestui strat sunt reprezentați de filtre învățabile, unde fiecare filtru reprezintă o mică bucată din imaginea de input. De exemplu, un filtru pentru acest strat poate avea dimensiunea de $5 \times 5 \times 3$, dimensiune ce reprezintă faptul că se iau 5 pixeli pe lațime, 5 pixeli pe înălțime și o adâncime de 3 pixeli, unde adâncimea reprezintă canalele RGB. În continuare se glisează fiecare filtru peste input și se compune produsul dintre filtre și input la fiecare poziție. În urma acestei operații se produce un vector de activare 2-dimensional care reprezintă răspunsul filtrului la fiecare poziție. Altfel spus, rețeaua va învăța filtre care au răspuns mai mare atunci când sunt prezente anumite tipuri de caracteristici, precum culoarea sau orientarea (vezi figura 2.10).
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_4}
	\caption[Exemplu de filtru aplicat peste input]{\textit{Exemplu de filtru aplicat peste input într-un strat convoluțional. Imagine preluată din \hyperlink{datameetsmedia}{[7]}.}}
\end{figure}   
  
  \item Stratul de pooling reprezintă o practică des folosită între mai multe straturi convoluționale succesive. Această operație reduce numărul de parametrii (dimensiunea modelului), operațiile din rețea și controlează overfitting-ul. Se execută indepedent pe fiecare nivel al adâncimii unui input și pastrează valoarea maximă a acelei zone (de cele mai multe ori). Rezultatul este o zonă de caracteristicii mai mică dar care păstrează cea mai relevantă statistică (vezi figura 2.11).
\begin{figure}[!tbp]
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_5}
    \caption{Reducerea dimensiunii.}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_6}
    \caption{Filtrul de $2\times2$ aplicat ce păstrează valoarea maximă.}
    \label{fig:f2}
  \end{subfigure}
  \caption[Exemplu de pooling]{\textit{Exemplu de pooling. Imagine preluată din \hyperlink{datameetsmedia}{[7]}.}}
\end{figure}
  
  \item Fully-Connected Layer este stratul în care caracteristicile sunt vectorizate pentru a putea fi folosite.
\end{enumerate}

\subsection{VGG}

VGG este o arhitectură clasică de rețea cu filtre convoluționale foarte mici, de dimensiune $3 \times 3$ și care poate avea un număr a straturilor de ponderi de 16 - 19. 

În ceea ce privește arhitectura (vezi figura 2.12), inputul în rețeaua convoluțională este de dimensiune fixă și anume $224 \times 224$ imagine RGB. Mai departe, imaginea este trecută printr-un set de straturi convoluționale unde sunt utilizate filtre de dimensiune mică, $3 \times 3$ - fiind cea mai mică dimensiune ce poate captura noțiunile de stânga/dreapta, sus/jos sau centru. Într-una dintre configurații se utilizează un filtru convoluțional de dimensiune $1 \times 1$. Pasul folosit pentru aplicarea filtrelor în straturile convoluționale este fixat la 1 pixel.

Poolingul este compus din cinci straturi de max-pooling care urmează după unele straturi convoluționale. Max-poolingul este calculat cu ferestre de $2\times2$ pixeli și cu pas de 2 pixeli.

Odată trecută imaginea prin straturile convoluționale și cele de pooling ajunge în trei straturi fully-connected. Primele două straturi au câte 4096 de canale fiecare, iar al treilea are 1000 de canale. Canalele celui de-al treilea strat sunt asociate claselor, fiecare canal reprezintă o clasă.

Ultimul strat din rețea este un strat soft-max \hyperlink{SimonyanKarenZissermanAndrew}{[10]}.

\begin{figure}[!h]
	\centering
	\includegraphics[max width=12cm,max height=12cm,keepaspectratio]{img_2_11}
	\caption[Configurații VGG]{\textit{Configurații ale rețelei VGG. Imagine preluată din \hyperlink{SimonyanKarenZissermanAndrew}{[10]}.}}
\end{figure}   

\subsection{InceptionV3}
Prima arhitectura de Inception a apărut sub numele de GoogLeNet. O a doua versiune de Inception a fost definită prin introducerea de batch-uri normalizate. Iar mai apoi, versiunea a treia în care a fost adăugată idea de factorizare.

Factorizarea în filtre convoluționale mici (vezi figura 2.13) presupune înlocuirea stratului cu filtru de dimensiune $5 \times 5$ cu două straturi de dimensiune $3 \times 3$ astfel reducându-se dimensiunea de la $5 \times 5 = 25$ la $3 \times 3 + 3 \times 3 = 18$.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=7cm,max height=7cm,keepaspectratio]{img_2_17}
	\caption[Factorizarea în filtre convoluționale mici]{\textit{Factorizarea în filtre convoluționale mici. Filtrul de dimensiune $5 \times 5$ înlocuit cu două de dimensiune $3 \times 3$. Imagine preluată din \hyperlink{guideinceptionv3}{[14]}.}}
\end{figure}   

Factorizarea spațială în convoluții asimetrice (vezi figura 2.14) presupune înlocuirea stratului cu filtru de dimensiune $3 \times 3$ cu două straturi de dimensiune $3 \times 1$ și $1 \times 3$ astfel reducându-se dimensiunea de la $3 \times 3 = 9$ la $3 \times 1 + 1 \times 3 = 6$. 
\begin{figure}[!h]
	\centering
	\includegraphics[max width=7cm,max height=7cm,keepaspectratio]{img_2_18}
	\caption[Factorizarea spațială în convoluții asimetrice]{\textit{Factorizarea în filtre convoluționale mici. Filtrul de dimensiune $3 \times 3$ înlocuit cu două de dimensiune $3 \times 1$ și $1 \times 3$.  Imagine preluată din \hyperlink{guideinceptionv3}{[14]}.}}
\end{figure}

Clasificatorul auxiliar (vezi figura 2.15) este utilizat în InceptionV3 ca regulizator și este poziționat în partea superioară a utimelor $17 \times 17$ straturi. Batch-urile normalizate sunt de asemenea folosite în clasificatorul auxiliar.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_19}
	\caption[Clasificator auxiliar]{\textit{Clasificatorul auxiliar. Imagine preluată din \hyperlink{guideinceptionv3}{[14]}.}}
\end{figure}

Reducerea eficientă a dimensiunii (vezi figura 2.16) se face prin utilizarea a două blocuri paralele, fie P și C. Primul dintre acestea, P, fiind un strat de activare de pooling (media sau maxim pooling). Ambele straturi au filtre cu pas 2 care sunt concatenate.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=17cm,max height=12cm,keepaspectratio]{img_2_20}
	\caption[Reducerea eficientă a dimensiunii]{\textit{Modulul care reduce dimensiunea. Diagrama din dreapta reprezintă aceași soluție însă din perspectiva dimensiunii rețelei. Imagine preluată din \hyperlink{guideinceptionv3}{[14]}.}}
\end{figure}   

Arhitectura completă este prezentată în figura 2.17.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=17cm,max height=12cm,keepaspectratio]{img_2_16}
	\caption[Arhitectura InceptionV3]{\textit{Arhitectura rețelei InceptionV3. Imagine preluată din \hyperlink{guideinceptionv3}{[14]}.}}
\end{figure}   


\subsection{ResNet}
Fie $H(x)$ maparea de bază unde $x$ reprezintă inputul. Funcția reziduală poate fi aproximată cu $F(x) := H(x) - x$, maparea de bază fiind $F(x) + x$.

\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_12}
	\caption[Învățarea reziduală]{\textit{Învățarea reziduală. Imagine preluată din \hyperlink{KaimingHeXiangyuZhangShaoqingRenJianSun}{[11]}.}}
\end{figure}  

Învățarea reziduală se aplică la câtva grupuri de straturi. Putem defini un bloc de straturi ca fiind 
\begin{align}
	y = F(x,\{W_i\}) + x
\end{align}
unde $x$ și $y$ reprezintă inputul și outputul straturilor considerate. Funcția $F(x, \{W_i\})$ reprezintă maparea reziduală ce trebuie învățată.

Dimensiunile lui $x$ și $F$ din ecuația de mai sus trebuie să fie egale. Redefinim ecuația după cum urmează
\begin{align}
	y = F(x,\{W_i\}) + W_sx
\end{align}
unde $W_s$ este o proiecție liniară a scurtăturilor conexiunilor pentru ca dimensiunile să se potrivească.

ResNet (vezi figura 2.19) pleacă de la o rețea simplă. Rețeaua simplă fiind inspirată de rețeaua VGG. Straturile convoluționale au în general filtre de dimensiune $3 \times 3$ și se bazează de două reguli de design: - pentru outputuri cu același număr de caracteristici, straturile vor avea același număr de filtre; - dacă numărul de caracteristicii este injumătățit, numărul de filtre este dublat astfel încât să fie păstrată complexitatea de timp pe strat.

\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=20cm,keepaspectratio]{img_2_13}
	\caption[Rețeaua ResNet]{\textit{Prima rețea (stânga) este o rețea VGG19. A doua rețea (centru) este o rețea simplă cu 34 de straturi. A treia rețea (dreapta) este o rețea reziduală cu 34 de straturi. Imagine preluată din \hyperlink{KaimingHeXiangyuZhangShaoqingRenJianSun}{[11]}.}}
\end{figure} 

Poolingul se realizează după straturile convoluționale cu un pas de 2 pixeli. Rețeaua se termină cu un strat de pooling mediu și un strat fully-connected softmax cu 1000 de canale.

Bazată pe rețeaua descrisă mai sus, rețeaua reziduală presupune inserția unor scurtături. Scurtăturile identice (vezi formula 2.26) pot fi direct utilizate când inputul și outputul au aceași dimensiune. Când dimensiunea crește considerăm două opțiuni: - scurtătura calculează în continuare maparea identității. Această opțiune nu introduce parametrii noi; - proiecția scurtăturii din formula 2.27 este utilizată pentru a potrivi dimensiunile. În ambele situații când se folosesc scurtăturile pentru a sări peste două straturi sunt calculate cu un pas de 2 pixeli. 

\subsection{NASNet}
NASNet este o arhitectură de rețea bazată pe tehnica de căutare Neural Architecture Search (NAS, figura 2.20). NAS presupune un controler cu o rețea neurală recurentă care conține mai multe rețele copii cu arhitecturi diferite. Rețelele copii sunt antrenate să conveargă pentru a obține o anumită precizie pe un set de antrenare. Rezultatele sunt utilizate pentru a actualiza controlerul ceea ce înseamnă că acest controler va genera arhitecturi mai bune în timp.
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=20cm,keepaspectratio]{img_2_14}
	\caption[NAS]{\textit{Privire de ansamblu asupra unei Neural Architecture Search. Imagine preluată din \hyperlink{Zoph2018LearningTA}{[13]}.}}
\end{figure}  

Plusul principal pe care îl aduce rețeaua NASnet este reprezentat de proiectarea unui nou spațiu de căutare astfel încât cea mai bună arhitectură pe setul de date CIFAR-10 poate scala către rezoluții ale imaginilor cât mai mari într-un interval definit. Astfel, acest spațiu poartă numele de \textit{NASNet search space}. În abordarea NASNet, arhitecturile rețelelor convoluționale sunt manual predeterminate, fiind compuse din celule convoluționale repetate de multe ori unde, fiecare celulă convoluțională are aceași arhitectură dar ponderi diferite.

Pentru a construi mai ușor arhitecturi scalabile pentru imagini de orice dimensiune este nevoie de două tipuri de celule convoluționale pentru a îndeplini două funcții principale: - celule convoluționale care returnează o hartă de caracteristici cu aceași dimensiune. Acest tip de celule se numește \textit{Celulă Normal}; - celule convoluționale care returnează o hartă de caracteristici cu înălțimea și lungimea harții divizată cu un factor doi. Acest tip de celule se numește \textit{Celulă de reducere} (vezi figura 2.21).
\begin{figure}[!h]
	\centering
	\includegraphics[max width=17cm,max height=17cm,keepaspectratio]{img_2_15}
	\caption[Celule normale și de reducere]{\textit{Celule normale (dreapta). Celule de reducere (stânga). Imagine preluată din \hyperlink{Zoph2018LearningTA}{[13]}.}}
\end{figure}  

\section{Clustere}

\subsection{Noțiuni generale}

Clusterizarea este un proces de grupare a unor articole în sensul în care articolele din același cluster sunt foarte similare între ele din punct de vedere al caracteristicilor. Această metodă este des utilizată în data mining, analiza datelor, machine learning, recunoașterea tiparelor sau regăsirea informației. Există mai multe tipuri de algoritmi de clusterizare, însă, ideea de bază este aceeași: clusterele sunt grupuri cu distanțe foarte mici între membrii grupului (fie distanța euclidiană, de exemplu).
\begin{figure}[!h]
	\centering
	\includegraphics[max width=10cm,max height=10cm,keepaspectratio]{img_2_21}
	\caption[Exemplu clustere]{\textit{Exemplu de două clustere (sus). Exemplu de trei clustere (jos). Imagine preluată din \hyperlink{dataclusteringtechniques}{[15]}.}}
\end{figure}  

Procesul de clustering poate fi împărțit în etape după cum urmează \hyperlink{dataclusteringtechniques}{[15]}:
\begin{enumerate}
	\item Colectarea datelor: alegerea articolelor pentru care se va aplica clusterizarea;
	\item Screening-ul inițial: presupune extragerea caracteristicilor relevante pentru fiecare articol din dataset;
	\item Reprezentarea: presupune pregătirea datelor pentru a putea fi folosite de către algoritmul de clusterizare, tot aici alegându-se și măsura de similaritate;
	\item Tendința de grupare: se verifică dacă datele au o tendință naturală de grupare; poate fi sărită pentru baze de date mari;
	\item Strategia de clusterizare: se alege algoritmul de clusterizare și parametrii inițiali;
	\item Validarea: se evaluează manual/vizual sau prin alte metode definite rezultatele obținute în urma clusterizări;
	\item Interpretarea: în această fază se compară rezultatele pe mai multe clustere, combinații de clustere și se trag concluziile.
\end{enumerate}

\subsection{Cei mai apropiați K vecini (kNN)}
KNN reprezintă un model de clasificare simplu și eficient în multe cazuri. Pentru ca un articol $t$ să fie clasificat sunt căutați cei mai propiați $k$ vecini formând regiunea lui $t$. Cei mai apropiați vecini sunt căutați cu o măsură de similaritate, de obicei distanța euclidiană sau similaritatea cosinus. Votul majoritar din acea regiune este folosit pentru a decide clasificarea lui $t$. $k$-ul este valoarea de care depinde destul de mult rata de succes a calsificării, cea mai simplă metodă de a alege un $k$ optim fiind reprezentată de rularea algoritmului pentru mai multe valori ale lui și observarea evoluției rezultelor.

\vspace{5mm}
Fie $D$ o colecție de $n$ clase cunoscute $\{d_1, d_2,..., d_n\}$. $Sim(d_i)$ - similaritatea celui mai indepărtat punct din regiunea locală, $N(d_i)$ - numărul de puncte din interiorul unei regiuni locale. Algoritmul de construcție al modelului este definit după cum urmează \hyperlink{gongdeguo}{[16]}:
\begin{enumerate}
	\item selectăm o măsură de similaritate și creăm o matrice de similaritate peste baza de date de antrenare;
	\item setăm toate datele cu eticheta neclasificate;
	\item pentru fiecare intrare cu eticheta de neclasificat căutăm cea mai mare regiune locală care acoperă cel mai mare număr de vecini cu aceași categorie.
	\item căutam intrarea $d_i$ cu cea mai mare regiune $N_i$ printre toate regiunile locale și creăm o reprezentare $<Cls(d_i), Sim(d_i), Num(d_i), Rep(d_i)>$ în modelul $M$ pentru a reprezenta toate intrările acoperite de regiunea $N_i$ și setăm etichete pentru toate aceste intrări;
	\item repetăm pași 3 și 4 până când toate intrările din baza de date de antrenare au fost clasificate;
	\item modelul $M$ este format din toate reprezentările setate în procesul de învățatare descris mai sus.
\end{enumerate}

Algoritmul de clasificare este definit după cum urmează:
\begin{enumerate}
	\item pentru ca o nouă intrare $d_t$ să fie clasificată, calculăm similaritatea ei cu toate celelalte reprezentări din model;
	\item dacă $d_t$ este acoperit doar de o reprezentare $<Cls(d_j), Sim(d_j), Num(d_j), Rep(d_j)>$ în sensul că distanța de la $d_t$ la $d_j$ este mai mică decât $Sim(d_j)$, $d_t$ este astfel clasificat ca făcând parte din clasa lui $d_j$;
	\item dacă $d_t$ este acoperit de două sau mai multe clase, clasificăm $d_t$ ca făcând parte din reprezentarea cu cea mai mare valoare a $Num(d_j)$, adică regiunea care acoperă cel mai mare număr de intrări din baza de date de antrenare;
	\item dacă nu există nicio reprezentare în modelul M care să acopere $d_t$, clasificăm $d_t$ cu o clasă nouă.
\end{enumerate}

Un exemplu vizual de execuție a algoritmului de kNN, parcurs pas cu pas, este prezentat în figura 2.23. Exemplu conține 36 de intrări din două clase marcate prin pătrat și cerc. Datele de test sunt reprezentate prin tringhiuri.
\begin{figure}[!h]
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_22}
    \caption{Distribuția inițială a datelor (stânga) și prima reprezentare obținută (dreapta)}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_23}
    \caption{A doua reprezentare obținută (stânga) și modelul înainte de triere (dreapta)}
    \label{fig:f2}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_24}
    \caption{Modelul după triere (stânga) și distribuția datelor de test (dreapta)}
    \label{fig:f3}
  \end{subfigure}
  \caption[Exemplu 1 de clasificare cu kNN]{\textit{Exemplu 1 de clasificare cu kNN. Imagine preluată din \hyperlink{gongdeguo}{[16]}.}}
\end{figure}  

Un al doilea exemplu de clasificare este prezentat în figura 2.24:
\begin{figure}[!h]
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_25}
    \caption{Prima reprezentare obținută (stânga) și a doua reprezentare obținută(dreapta)}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img_2_26}
    \caption{A treia reprezentare obținută (stânga) și modelul final (dreapta)}
    \label{fig:f2}
  \end{subfigure}
  \caption[Exemplu 2 de clasificare cu kNN]{\textit{Exemplu 2 de clasificare cu kNN. Imagine preluată din \hyperlink{gongdeguo}{[16]}.}}
\end{figure}

\subsection{Metrici de evaluare a clusterelor}

\subsubsection{Coeficientul silhouette}

Coeficientul (vezi formula 2.10) este folosit pentru a evalua clusterele în învățarea nesupervizată. Este calculat utilizând distanța euclidiană medie intra-clustere ($a$) și distanța medie către cel mai apropiat cluster ($b$) pentru fiecare intrare, adică distanța dintre o intrare și cel mai apropiat cluster din care nu face parte. Numărul de etichete trebuie să respecte constrangerea $2 \leq nr_{etichete} \leq nr_{etichete} - 1$. Valorile returnate de acest coeficient sunt cuprinse în intervalul $[-1, 1]$. Valorile apropiate de 0 indică clustere care se suprapun, valorile negative în general indică că există intrări asignate în clusterul greșit, iar valorile apropiate de 1 indică o separație bună între clustere \hyperlink{silhouette}{[17]}.
\begin{align}
	\frac{b-a}{max(a,b)}
\end{align}
